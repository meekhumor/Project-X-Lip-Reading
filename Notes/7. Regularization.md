## Regularization

- It's a technique used in machine learning to prevent a common problem called overfitting.

  _Overfitting happens when a model becomes too complex and starts to memorize the training data instead of learning the underlying patterns._

### 1. Logistic Regression

- In logistic regression, we try to minimize a cost function called J. To add regularization, we introduce a parameter called lambda.
- Regularization is applied to the parameter w. We add a term to the cost function that includes lambda, the norm of w squared, and some other constants.
- This term helps to make the parameter values smaller, reducing the complexity of the model.
- It's like adding a constraint that encourages the model to focus on the important patterns in the data rather than memorizing every detail.

```
J = (1/m) * sum(-y * log(h(x)) - (1-y) * log(1 - h(x))) + (lambda/(2*m)) * sum(w^2)
```

### 2. Neural Network

**Why regularization reduces overfitting?**

Imagine you are trying to fit a puzzle together. If you have too many puzzle pieces, it becomes difficult to find the right fit, and you might end up forcing pieces together that don't actually belong. This is similar to overfitting in machine learning.

_Regularization acts like a constraint that limits the complexity of the puzzle, making it easier to find the correct fit._

### 3. Dropout Regularization

- Dropout works by randomly removing some nodes (or neurons) from each layer of the network during training.
- This creates a smaller and less complex network.
- By training the network with these smaller, randomly modified versions, dropout helps to regularize the network and prevent overfitting.
- It's like training multiple different networks on different subsets of the data.

**Why does dropout works**

- We randomly remove some workers from the team on each iteration. This means that the team becomes smaller, and each worker has to be more versatile and not rely too much on any one task.
- This helps prevent the team from becoming too specialized and ensures that they can handle different tasks well.

### 4. 