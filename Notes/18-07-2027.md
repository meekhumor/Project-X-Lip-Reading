#### Making good choices

- Applied ML is a higly iterative processs \
   idea -> code -> experiment (repeat)
- Hyperparameter (layers, hidden units, learning rates, activation funtion) are adjusted after going through the above cycle multiple times to make a good choice.

#### Train/ dev/ tests sets

- Splitting up the dataset into training, development, and test sets will make the process more efficient.
- Nowdays generally it is splitted into 98% training set, 1% dev set and 1% test set.
- Training algorithms on training sets, development sets to see which model works best and the best model is then evaluated using test sets.
- Make sure train and test sets comes from same distribution
- It okay not having a test set (only dev set)

#### Bias and Variance

![alt text](Bias-variance-trade-off-in-machine-learning-This-figure-illustrates-the-trade-off.png)

|                           | Train set error | Dev set error |
| ------------------------- | --------------- | ------------- |
| High variance             | 1%              | 11%           |
| High bias                 | 15%             | 16%           |
| High bias & high variance | 15%             | 30%           |
| High bias & high variance | 0.5%            | 1%            |

    1. High bias
        - Bigger network
        - Train longer

    2. High Variance
        - More data
        - Regularization

#### Regularization

- Adding regularization helps prevent overfitting and reduce variance in neural network
